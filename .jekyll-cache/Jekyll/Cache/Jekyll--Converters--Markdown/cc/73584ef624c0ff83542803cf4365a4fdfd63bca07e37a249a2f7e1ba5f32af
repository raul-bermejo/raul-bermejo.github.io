I"‰<p>In this project, Iâ€™ll be using Natural Language Processing (NLP) to study an SMS dataset. Iâ€™m interested to understand whether NLP can tell us something about the nature of SMS.</p>

<p>For the chosen dataset, I hope to answer some of the following questions:</p>

<ul>
  <li>What words are used most frequently in English SMS texting?</li>
  <li>Is NLP a good tool to study short text like SMS?</li>
  <li>Whatâ€™s the main sentiment(s) of SMS texts as captured by basic NLP tools?</li>
  <li>What are some potential sources of bias when studying SMS datasets?</li>
</ul>

<p>In part I of this series I will focus on the pre-processing of the data 
The main goal of this project is to showcase those who are not NLP experts (like me) the value of basic NLP tools. 
So letâ€™s dive right in! First, Iâ€™ll import some neccesary packages and then have a look at the dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td> --><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">jupyterthemes</span> <span class="kn">import</span> <span class="n">jtplot</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display_html</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span><span class="p">,</span><span class="n">cycle</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="p">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s">'retina'</span>                                    <span class="c1"># so you can see plots in HD :)
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s">"whitegrid"</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">set_palette</span><span class="p">(</span><span class="s">"colorblind"</span><span class="p">)</span>
<span class="n">COLORS</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s">"deep"</span><span class="p">,</span> <span class="mi">12</span><span class="p">).</span><span class="n">as_hex</span><span class="p">()</span>

<span class="n">darkmode_on</span> <span class="o">=</span> <span class="bp">True</span>
<span class="k">if</span> <span class="n">darkmode_on</span><span class="p">:</span>
    <span class="n">jtplot</span><span class="p">.</span><span class="n">style</span><span class="p">(</span><span class="n">theme</span><span class="o">=</span><span class="s">'grade3'</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="s">'talk'</span><span class="p">,</span> <span class="n">ticks</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">grid</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    
<span class="k">def</span> <span class="nf">display_side_by_side</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="n">titles</span><span class="o">=</span><span class="n">cycle</span><span class="p">([</span><span class="s">''</span><span class="p">])):</span>
    <span class="n">html_str</span><span class="o">=</span><span class="s">''</span>
    <span class="k">for</span> <span class="n">df</span><span class="p">,</span><span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">chain</span><span class="p">(</span><span class="n">titles</span><span class="p">,</span><span class="n">cycle</span><span class="p">([</span><span class="s">'&lt;/br&gt;'</span><span class="p">]))</span> <span class="p">):</span>
        <span class="n">html_str</span><span class="o">+=</span><span class="s">'&lt;th style="text-align:center"&gt;&lt;td style="vertical-align:top"&gt;'</span>
        <span class="n">html_str</span><span class="o">+=</span><span class="sa">f</span><span class="s">'&lt;h2&gt;</span><span class="si">{</span><span class="n">title</span><span class="si">}</span><span class="s">&lt;/h2&gt;'</span>
        <span class="n">html_str</span><span class="o">+=</span><span class="n">df</span><span class="p">.</span><span class="n">to_html</span><span class="p">().</span><span class="n">replace</span><span class="p">(</span><span class="s">'table'</span><span class="p">,</span><span class="s">'table style="display:inline"'</span><span class="p">)</span>
        <span class="n">html_str</span><span class="o">+=</span><span class="s">'&lt;/td&gt;&lt;/th&gt;'</span>
    <span class="n">display_html</span><span class="p">(</span><span class="n">html_str</span><span class="p">,</span><span class="n">raw</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="dataset">Dataset</h2>

<p>The dataset used for this analysis compromises 71,000 messages focusing on English and Mandarin Chinese. The dataset is open sourced (at the time of writing) and <a href="http://wing.comp.nus.edu.sg/SMSCorpus">available here</a>. The details the dataset are also described in <a href="https://rdcu.be/cR1jY">Chen, T., Kan, MY. Creating a live, public short message service corpus: the NUS SMS corpus</a>, authored by the researchers who also collected the data.</p>

<p>Letâ€™s quickly have a look at the data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td> --><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1"># extract dataset
</span><span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/clean_nus_sms.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df_raw</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># explore datset
</span><span class="k">print</span><span class="p">(</span><span class="n">df_raw</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
<span class="n">df_raw</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre>Index(['id', 'Message', 'length', 'country', 'Date'], dtype='object')
</pre></td></tr></tbody></table></code></pre></div></div>

<p>There are not many columns in the dataset, which makes it easier to stratify it or bin it. We could choose to bin it based on the <code class="language-plaintext highlighter-rouge">length</code> or <code class="language-plaintext highlighter-rouge">Date</code> columns but given that weâ€™re taking an NLP approach and that language is normally country-depdendant. Because of that, letâ€™s look at the distribution of the data based on the country:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td> --><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>

<span class="n">sns</span><span class="p">.</span><span class="n">histplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s">'country'</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
    <span class="n">color</span><span class="o">=</span><span class="n">COLORS</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s">'log'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'SMS count per country (LOGSCALE)'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'countries'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">'count'</span><span class="p">)</span>

<span class="n">locs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">setp</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="../../assets/img/nlp/sms_dist_all.png" alt="png" /></p>

<p>Noticing that the counts (x-axis) in the distribution are in log-scale, we see that we have a lot of data (SMS) for countries like Singapore (&gt;10,000), whereas for most countries we only have around 10 SMS. For this analysis, letâ€™s only consider countries that have at least 1,000 SMS, and consider other bins of data to have an insuficient sample size for our analysis.</p>

<p>However, we need to be careful because countries like Singapore or the USA two codes: â€˜SGâ€™ and â€˜Singaporeâ€™. For simplicity and consistency, Iâ€™ll change â€˜SGâ€™ to â€˜Singaporeâ€™ and â€˜United Statesâ€™ to â€˜USAâ€™. So we need to do a bit of data wrangling:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre></td> --><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">spacy</span> <span class="k">as</span> <span class="n">sp</span>

<span class="c1"># change 'SG' to 'Singapore' and 'United states country' to 'USA'
</span><span class="n">mask_sg</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'country'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'SG'</span>
<span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_sg</span><span class="p">,</span> <span class="s">'country'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'Singapore'</span>

<span class="n">mask_usa</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'country'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'United States'</span>
<span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask_usa</span><span class="p">,</span> <span class="s">'country'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'USA'</span>

<span class="c1"># group by country
</span><span class="n">count_label</span> <span class="o">=</span> <span class="s">'count_sms'</span>
<span class="n">df</span><span class="p">[</span><span class="n">count_label</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">grouped_country</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'country'</span><span class="p">,</span> <span class="n">as_index</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="n">count_label</span><span class="p">].</span><span class="n">count</span><span class="p">()</span>

<span class="c1"># find what countries have a sample size greater than the threshold defined
</span><span class="n">NSAMPLE_THD</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">valid_countries</span> <span class="o">=</span> <span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="s">'country'</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">grouped_country</span><span class="p">.</span><span class="n">iterrows</span><span class="p">()</span> <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="n">count_label</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">NSAMPLE_THD</span><span class="p">]</span>

<span class="c1"># filter out countries that have a statistically suficient sample size
</span><span class="n">df_temp</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'country'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">valid_countries</span><span class="p">)].</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">data_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">'Message'</span><span class="p">,</span>
    <span class="s">'length'</span><span class="p">,</span>
    <span class="s">'country'</span><span class="p">,</span>
    <span class="s">'Date'</span>
<span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">df_temp</span><span class="p">[</span><span class="n">data_cols</span><span class="p">]</span>
<span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># filter out countries that don't meet criteria in grouped df
</span><span class="n">grouped_country</span> <span class="o">=</span> <span class="n">grouped_country</span><span class="p">[</span><span class="n">grouped_country</span><span class="p">[</span><span class="s">'country'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">valid_countries</span><span class="p">)].</span><span class="n">sort_values</span><span class="p">(</span><span class="n">count_label</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># plot filtered distribution
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">barplot</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">grouped_country</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="s">'country'</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="n">count_label</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
    <span class="n">color</span><span class="o">=</span><span class="n">COLORS</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">ax</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">'countries'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'SMS count per country (n &gt; 1000 SMS)'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="../../assets/img/nlp/sms_dist_filtered.png" alt="png" /></p>

<p>That looks much neater! Also, it means that the analysis will be more statistically meaningful. One should note however that because the study was performed in Singapore, thereâ€™s an oversampling for Singapore datapoints. Given the other populations, we could randomly decimate the data for Singapore, but I wonâ€™t be doing that in this analysis.</p>

<h2 id="text-pre-preprocessing">Text Pre-Preprocessing</h2>

<p>For this project, the NLP library I chose is <a href="https://spacy.io/usage/spacy-101">spaCy</a>, because it allows one to customize and add components to NLP pipelines. In this context, a pipeline refers to different analytical tools or pre-rpocessing techniques to extract insight from text, such as the [<em>lemmatizer</em>]https://en.wikipedia.org/wiki/Lemmatisation) (which loosely speaking extract the â€˜rootâ€™ of a word) or the <em>tagger</em> (which assigns <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging#:~:text=In%20corpus%20linguistics%2C%20part%2Dof,its%20definition%20and%20its%20context.">part-of-speech</a> tags to the words).</p>

<p>Now into the fun part! Before we start using NLP tools, we need to clean our data. In NLP, this means that weâ€™ll need to do some text pre-processing. For example, we might want to remove words that appear very often but are not very insightful, like â€˜aâ€™, â€˜anâ€™. These words are known as <em>stopwords</em>.</p>

<p>Part of the pre-processing also entails building a good data-structure to embed the text data. Initially, I set to build a data-structure for the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> (text-dataset) that would allow me to keep track of what country each SMS corresponds to. One can achieve that through annotations, and as mentioned before, the great thing about <code class="language-plaintext highlighter-rouge">spaCy</code> is that it allows one to customize elements of the <code class="language-plaintext highlighter-rouge">nlp()</code> pipeline. In this case, it meant that I added the country as an attribute extension to the <code class="language-plaintext highlighter-rouge">Doc</code> object:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td> --><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">spacy.tokens</span> <span class="kn">import</span> <span class="n">Doc</span>

<span class="n">add_annotations</span> <span class="o">=</span> <span class="bp">False</span>
<span class="k">if</span> <span class="n">add_annotations</span><span class="p">:</span>
    <span class="n">Doc</span><span class="p">.</span><span class="n">set_extension</span><span class="p">(</span><span class="s">'country'</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s">"Message"</span><span class="p">,</span><span class="s">"country"</span><span class="p">]].</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">).</span><span class="nb">apply</span><span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">values</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>However, upon some exploration I realised that the problem would be more challenging as some of these countries have a rich variety of languages (e.g. <a href="https://en.wikipedia.org/wiki/Languages_of_Singapore">Singapore</a> and <a href="https://en.wikipedia.org/wiki/Languages_of_India">India</a>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td> --><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span>
    <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'country'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'Singapore'</span><span class="p">].</span><span class="n">Message</span><span class="p">.</span><span class="n">values</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span>
    <span class="s">'='</span><span class="o">*</span><span class="mi">180</span><span class="o">+</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span>
    <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'country'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'India'</span><span class="p">].</span><span class="n">Message</span><span class="p">.</span><span class="n">values</span><span class="p">[:</span><span class="mi">10</span><span class="p">],</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">,</span>
    <span class="s">'='</span><span class="o">*</span><span class="mi">180</span>
<span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td> --><td class="rouge-code"><pre>['Bugis oso near wat...'
 'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'
 'I dunno until when... Lets go learn pilates...'
 'Den only weekdays got special price... Haiz... Cant eat liao... Cut nails oso muz wait until i finish drivin wat, lunch still muz eat wat...'
 'Meet after lunch la...'
 'm walking in citylink now Ã¼ faster come down... Me very hungry...'
 '5 nights...We nt staying at port step liao...Too ex'
 'Hey pple...$700 or $900 for 5 nights...Excellent location wif breakfast hamper!!!'
 'Yun ah.the ubi one say if Ã¼ wan call by tomorrow.call 67441233 look for irene.ere only got bus8,22,65,61,66,382. Ubi cres,ubi tech park.6ph for 1st 5wkg days.Ã¨n'
 'Hey tmr maybe can meet you at yck'] 
 ====================================================================================================================================================================================
 ['K' 'Studying?' 'Vch photo' 'K:-)ya i hav to finish' 'One senioq akka'
 'K d' 'She vil mistake me only cha.dnt talk to me also'
 'I am standing up' 'Sorry d v seriously forgot' 'Free'] 
 ====================================================================================================================================================================================
</pre></td></tr></tbody></table></code></pre></div></div>

<p>An English-trained model like <code class="language-plaintext highlighter-rouge">en_core_web_sm</code> wonâ€™t perform well on corpa with a diversity of languages, thus any insights drawn from the results would be biased to English-text patterns. So I decided to build a pre-processing pipeline for USA messages and then re-use the the pipeline for other countries on a different project.</p>

<p>The main point of this pre-processing pipeline is to: (i) get rid of stopwords and (ii) extract the lemmas in the text (root of each word thatâ€™s still readable).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td> --><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>

<span class="c1"># extract stopword set and update with more colloquial words
</span><span class="n">stop_words</span> <span class="o">=</span> <span class="p">{</span><span class="n">s</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">)}</span>

<span class="c1"># load model, get a subsample of the model and extract lemmas
</span><span class="n">nlp</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'en_core_web_sm'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">text_preprocessing_pipeline</span><span class="p">(</span><span class="n">country</span><span class="p">):</span>
    <span class="s">'''
    Find lemmas and pos_tag of a subset of SMS based on
    country of origin
    '''</span>

    <span class="n">country_sms</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s">'country'</span><span class="p">]</span> <span class="o">==</span> <span class="s">'USA'</span><span class="p">]</span>
    <span class="n">country_docs</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">country_sms</span><span class="p">[</span><span class="s">'Message'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>

    <span class="n">lemmas</span><span class="p">,</span> <span class="n">pos_tags</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">country_docs</span><span class="p">:</span>
        <span class="n">lemma_i</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span><span class="p">.</span><span class="n">lemma_</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">token</span><span class="p">.</span><span class="n">lemma_</span><span class="p">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">token</span><span class="p">.</span><span class="n">lemma_</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lemma_i</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lemmas</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">lemma_i</span><span class="p">))</span>
        
        <span class="n">pos_tags_i</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">.</span><span class="n">text</span><span class="p">:</span> <span class="n">token</span><span class="p">.</span><span class="n">pos_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">}</span>
        <span class="n">pos_tags</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pos_tags_i</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">lemmas</span><span class="p">,</span> <span class="n">pos_tags</span>
            
<span class="c1"># run preprocess pipeline for USA
</span><span class="n">lemmas</span><span class="p">,</span> <span class="n">pos_tags</span> <span class="o">=</span> <span class="n">text_preprocessing_pipeline</span><span class="p">(</span><span class="n">country</span><span class="o">=</span><span class="s">'USA'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="next-steps">Next Steps</h2>

<p>Now that we have pre-processed the dataset (extracting the lemmas and removing stopwords), we can actually move on to analyse the corpus using NLP tools. That will require somehow turning text into numbers and numerical objects that can be analysed and processed more easily. If youâ€™re interested, you can read further on <a href="/posts/nlp-sms-part2/">NLP analysis on SMS text - part II</a>!</p>
:ET