<!DOCTYPE html>













<html lang="en"
  
    data-mode="light"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Allow having a localized datetime different from the appearance language -->
  
    <meta name="prefer-datetime-locale" content="en-au">
  

  

    

    

  

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="The Productionisation of AI/ML - ‘The Golden Era’ or ‘The Wild West’?" />
<meta name="author" content="raul" />
<meta property="og:locale" content="en" />
<meta name="description" content="This blogpost was originally released through the Good Data Institute (GDI), where I work as a Fellow to to give not-for-profits access to data analytics support &amp; tools for social and environmental good. If you’d like to learn more about GDI, check their website here." />
<meta property="og:description" content="This blogpost was originally released through the Good Data Institute (GDI), where I work as a Fellow to to give not-for-profits access to data analytics support &amp; tools for social and environmental good. If you’d like to learn more about GDI, check their website here." />
<link rel="canonical" href="http://localhost:4000/posts/fml-part1/" />
<meta property="og:url" content="http://localhost:4000/posts/fml-part1/" />
<meta property="og:site_name" content="Raul Bermejo" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-10-17T11:00:00+10:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="The Productionisation of AI/ML - ‘The Golden Era’ or ‘The Wild West’?" />
<meta name="twitter:site" content="@twitter_username" />
<meta name="twitter:creator" content="@raul" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"raul"},"dateModified":"2023-10-26T11:21:13+10:00","datePublished":"2022-10-17T11:00:00+10:00","description":"This blogpost was originally released through the Good Data Institute (GDI), where I work as a Fellow to to give not-for-profits access to data analytics support &amp; tools for social and environmental good. If you’d like to learn more about GDI, check their website here.","headline":"The Productionisation of AI/ML - ‘The Golden Era’ or ‘The Wild West’?","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/fml-part1/"},"url":"http://localhost:4000/posts/fml-part1/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>The Productionisation of AI/ML - ‘The Golden Era’ or ‘The Wild West’? | Raul Bermejo
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Raul Bermejo">
<meta name="application-name" content="Raul Bermejo">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  

    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  
</head>


  <body data-spy="scroll" data-target="#toc" data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" class="mx-auto">
        
          
          <img src="/assets/img/face_image.jpg" alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title mt-3">
      <a href="/">Raul Bermejo</a>
    </div>
    <div class="site-subtitle font-italic">Data Engineer @ Versent (AU)
Fellow @ Good Data Institute

</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/categories/" class="nav-link">
        <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CATEGORIES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/cv/" class="nav-link">
        <i class="fa-fw fas fa-address-card ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>CV</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    

    
      

      
      <a href="https://github.com/raul-bermejo" aria-label="github"
        target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="https://www.linkedin.com/in/raul-bermejo-059b94208" aria-label="linkedin"
        target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['raulbv.personal','gmail.com'].join('@')" aria-label="email"
        >
        <i class="fas fa-envelope"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper">
  <div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>The Productionisation of AI/ML - ‘The Golden Era’ or ‘The Wild West’?</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container pl-xl-4 pr-xl-4">

        









<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4">
    <div class="post pl-1 pr-1 pl-md-2 pr-md-2">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Add attribute 'hide-bullet' to the checkbox list -->



<!-- images -->




  
  

  
    
      
      
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  




<!-- Wrap prompt element of blockquote with the <div> tag -->







<!-- return -->





<h1 data-toc-skip>The Productionisation of AI/ML - ‘The Golden Era’ or ‘The Wild West’?</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      Posted
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1665968400"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Oct 17, 2022
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      Updated
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1698283273"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Oct 26, 2023
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author -->
    <span>
      
      

      

      By

      <em>
        
        Raul Bermejo
        
      </em>
    </span>

    <div>
      <!-- page views -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="2875 words">
  <em>15 min</em> read</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p><em>This blogpost was <a href="https://www.gooddatainstitute.com/post/the-productionisation-of-ai-ml-the-golden-era-or-the-wild-west">originally released through the Good Data Institute (GDI)</a>, where I work as a Fellow to to give not-for-profits access to data analytics support &amp; tools for social and environmental good. If you’d like to learn more about GDI, <a href="https://www.gooddatainstitute.com/about">check their website here</a>.</em></p>

<p><img data-src="../../assets/img/fml/thumbnail-fml1.jpg" alt="jpg" data-proofer-ignore></p>

<div align="center">Picture taken in Aotearoa New Zealand</div>
<p> </p>

<p>Data Science has come to permeate almost every aspect of our society. Machine Learning and Artificial Intelligence (AI/ML) algorithms are being deployed at scale to facilitate our daily lives. Whether it’s filtering our spam emails, giving us directions, or nudging what we watch on streaming platforms, this technology has integrated seamlessly with our digital lives. These algorithms are also present in pivotal aspects of our lives, for example, by deciding whether we’ll be short-listed for an interview, or whether our bank loan will be approved. Meanwhile, in the public sector, algorithms are becoming more critical for decision-makers in both the policy and legal spheres.</p>

<p>Over the last 50 years, Hollywood has painted a picture of a long-term AI apocalypse where civilisation would be destroyed by killer robots. However, the last decade has revealed a more sneaky reality: even today, AI/ML is creating harm in our society and it has the potential to further scale up injustice and unfairness.</p>

<p>This post is the first part of a series about Ethics and Data Science. In this part, I will discuss the current picture mentioned above by describing the challenges present, outlining some examples of harmful AI/ML algorithms and discussing how this harm stems from the root. More importantly, I will propose some actionable items that organisations and data practitioners can take to leverage a fair use of data. Whether you are a data professional or simply interested in this topic, I hope to convince you of the importance of ethical practices in Data Science.</p>

<h2 id="challenges"><span class="mr-2">Challenges</span><a href="#challenges" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Despite Hollywood’s post-apocalyptic depiction of AI, I don’t think AI/ML algorithms are inherently evil. They are powerful tools that can be used for the benefit or detriment of our society. So how could they become harmful at all? One of the main issues we face is that these algorithms learn behaviour from data about <em>how the world is,</em> instead of <em>how the world should be</em>. To clarify this point, let’s consider the following quote [3]:</p>

<blockquote>
  <p><em>Statistical and machine learning models are designed to identify patterns in the data used to train them. As such, they will reproduce, to the extent that they are predictive, unfair patterns encoded in the data or unfairness in the problem formulation described above</em>.</p>
</blockquote>

<p>That is, these algorithms have the power to amplify whatever is present in the data that the algorithm is trained on. If there are unfair or biased patterns in the data, these will be reflected in the output of the algorithm. The challenge is that by default, the data used as input in these algorithms is biased towards unfairness and underrepresentation. The concept of bias is useful as it can help us understand under what circumstances these AI/ML algorithms become unfair. But how does this harm originate in the first place and what exactly do I mean by bias?</p>

<h3 id="bias-in-data-science"><span class="mr-2">Bias in Data Science</span><a href="#bias-in-data-science" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>In the context of this series, bias relates to outcomes of AI/ML algorithms that favour subsets of the population based on a human factor (age, gender, disability, ethnicity, ….). At the most general level, one can think of two main sources of bias related to Data Science:</p>

<ol>
  <li>
    <p><strong>Statistical Bias:</strong> The systematic discrepancy between the data used to train an AI/ML algorithm and the world as it is. This type of bias normally occurs when the training data is not representative of the full population [3]. For example, a study found that most off-the-shelf Computer Vision (CV) algorithms are trained with oversampled white facial images because the data was mostly collected in Western Countries [6].</p>
  </li>
  <li>
    <p><strong>Societal Bias:</strong> The ensemble of non-statistical social structures that make fair decision-making by a model more difficult or even impossible. For example, even if we could measure crime 100% accurately, there might be a normative bias due to an unjust policing system even if there’s no statistical bias.</p>
  </li>
</ol>

<p><img data-src="../../assets/img/fml/fig1-fml1.png" alt="png" data-proofer-ignore></p>

<div align="center">Figure courtesy of Mitchell et al. 2018 [3].</div>
<p> </p>

<p>Addressing issues of societal bias may require adjusting data collection processes, or unfortunately may not have a technical solution at all. Moreover, these two types of biases overlap with each other. For example, societal bias might affect the definition of how crime is defined, thus introducing statistical bias. In this series, I will mainly be focusing on statistical bias, as I think it’s easier to tackle algorithmically for individual data practitioners developing AI/ML products. However, because of the interconnectedness between societal and statistical bias, societal bias will naturally creep in throughout the series. For the interested reader, there have been some proposals in the literature to directly tackle societal bias in Data Science, for instance by embracing the notion of Intersectionalism (you can read more in this paper [2]).*</p>

<p>Recognising these biases requires a retrospective understanding of how systematic injustice has manifested and developed in many domains over time. To leverage fair AI/ML products, professionals will benefit from upskilling in non-technical areas. For example, critical race theory will help practitioners understand the systematic underrepresentation of marginal groups in datasets. However, having to upskill in non-technical aspects of fairness will make many uncomfortable. I don’t mean morally uncomfortable (at least I would hope so), but in a constantly evolving tech-world where professionals have to constantly learn new tools and frameworks to keep up with industry, having to upskill in something outside of their domain of expertise will add more pressure to individuals as well as excuses for organisations to not develop AI/ML algorithms fairly. This is where organisations need to support individuals with the resources and encouragement to upskill in these non-technical areas. All organisations (whether big or small), should strive to make Data Ethics the norm and not a ‘would be nice’.</p>

<h3 id="productionisation-of-aiml-the-golden-era-or-the-wild-west"><span class="mr-2">Productionisation of AI/ML: ‘The Golden Era’ or the ‘Wild West’?</span><a href="#productionisation-of-aiml-the-golden-era-or-the-wild-west" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>In the last decade we’ve seen an explosion of harmful examples of AI/ML algorithms. However, these algorithms have been around for a lot longer in academia and industry research. For example, <a href="https://www.lifewire.com/oxo-aka-noughts-and-crosses-729624">OXO was released in 1952 as the first algorithm that could play the perfect game of tic-tac-toe</a>. More triumphantly, <a href="https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/#:~:text=On%20May%2011%2C%201997%2C%20an,the%20champion%20and%20three%20draws">in 1997 IBM’s Deep Blue algorithm beat the world chess champion</a>. So what has gone wrong in the last few years? In my opinion, the productionisation of AI/ML by market forces has accelerated the harm AI/ML algorithms pose to our society. But what exactly do I mean by productionisation of AI/ML?</p>

<p>Both executives and investors are celebrating the ‘<a href="https://www.forbes.com/sites/joemckendrick/2019/10/23/artificial-intelligence-enters-its-golden-age/?sh=4a18cf1e734e">Golden Era of AI</a>’, pouring millions into the development of AI/ML algorithms to derive profit while making their business success reliant on this technology. <a href="https://www.relx.com/~/media/Files/R/RELX-Group/documents/reports/misc/2019-relx-emerging-tech-summary.pdf">A survey of 1000 U.S. senior executives</a> found that ‘93% of respondents say that emerging technologies, including deep learning, machine learning, and artificial intelligence, help their businesses be more competitive’.</p>

<p>By now, there’s no doubt that AI/ML has immense potential to create business value. It’s no coincidence that the most successful tech companies are embedding AI/ML in the core of their products (think of Netflix, Spotify, Youtube, Amazon, …). However, when hearing business professionals talk of the ‘Golden Era of AI’ and its opportunities, I find it hard not to think of the Californian ‘Gold Rush’ in the 19th century. Historically, gold turned this land into the ‘Wild West’, and amongst other things, it led to the <a href="https://www.iitc.org/gold-greed-genocide/">mass massacre and displacement of Native Americans</a> in the area. While AI/ML has not got to that stage yet, the ‘AI/ML Rush’ is much more scalable and present in our society than gold mining. It’s also not short of harmful examples even today.</p>

<p>For instance, in 2015 the <a href="https://www.bbc.com/news/technology-33347866">Google Photos app mistakenly labeled African American people as ‘Gorillas’</a>. More recently, OpenAI released DALL-E 2, an AI/ML algorithm that takes written text as input and generates an image from scratch. When instructed to produce images for trades that are stereotypically based on gender or race, <a href="https://www.vice.com/en/article/wxdawn/the-ai-that-draws-what-you-type-is-very-racist-shocking-no-one">DALL-E generates racial and gender-biased images</a>. While OpenAI acknowledged this bias in their release statement, I don’t think acknowledgment leads to justification in this case. If you don’t think that’s enough examples, you can find <a href="https://levity.ai/blog/ai-bias-how-to-avoid">more real-life examples of biased AI/ML products in this article</a>.</p>

<p>By this point, you might argue that all these examples might have offended subsets of the population, but have not caused ‘real harm’ to anyone. However, considering the influence of AI/ML in the legal system might change your opinion. For example, a software company called <a href="https://www.equivant.com/">Equivant</a> developed COMPAS, an AI/ML algorithm that uses data from previous offenders to predict the risk of recidivism (re-offending). After it had been deployed in production, this algorithm has been <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">shown to suffer from both gender and racial bias</a>. That is, COMPAS is more likely to tag black people and males as high-risk than white people and females respectively.</p>

<p>Just like in the Hollywood depiction of the ‘Wild West’, it’s become a common practice for AI/ML organisations and data professionals to ‘shoot first and ask questions later’. Personally, I would be dubious of any AI/ML advocate who hails the ‘Golden Era of AI’ without acknowledging all the potential harms associated with AI/ML products.</p>

<h2 id="opportunities"><span class="mr-2">Opportunities</span><a href="#opportunities" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>We’ve learned that data practitioners and organisations face challenges to leverage AI/ML products ethically. Given the lay of the land I’ve outlined above, there are many opportunities for organisations to leverage a fair use of data. The good news is that even smaller organisations have the potential to become champions in this space and lead the way.</p>

<h3 id="how-can-organisations-leverage-ethical-practices-around-data-science"><span class="mr-2">How can organisations leverage ethical practices around Data Science?</span><a href="#how-can-organisations-leverage-ethical-practices-around-data-science" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Over the last years, we’ve seen many tech organisations come up with codes of conduct or set of principles for ethical data science (e.g. <a href="https://www.microsoft.com/en-us/ai/responsible-ai-resources">Microsoft</a>, <a href="https://ai.google/principles/">Google</a>, <a href="https://www.ibm.com/blogs/think/2017/01/ibm-cognitive-principles/">IBM</a> or <a href="https://www.intel.com/content/dam/www/public/us/en/ai/documents/Intels-AI-Privacy-Policy-White-Paper-2018.pdf">Intel</a>). More recently, these codes of conduct are becoming more tokenistic as we’ve seen companies being involved in AI/ML scandals even when their code of conduct was being ‘followed’. Here’s a list of actionable steps that organisations can use to mitigate the potential harms of AI/ML products:</p>

<ul>
  <li>
    <p><strong>Make your organisation accountable:</strong> Having an ethical code of conduct is (or should be) a statement of <em>intent</em> for wanting to leverage data science ethically. However, at the end of the day, intent is not nearly as important as <em>outcome and results</em> [4] (p.100-110). Therefore, organisations need to make themselves explicitly accountable when they deploy biased AI/ML products. ‘Faking ethics’ should be regarded as detrimental as faking data or results [8], and hopefully the legal system will leverage this accountability too.</p>
  </li>
  <li>
    <p><strong>Understand the trade-offs:</strong> Developing AI/ML products comes at a cost. For example, what should organisations do when there’s no available data from a given population sub-group, thus leading to statistical bias? One can spend more resources collecting an even number of representative data samples or tackle this challenge with algorithmic tools (e.g. data augmentation in Computer Vision). However, these methods are time- and resource-consuming, and as such organisations must be willing to pay the price of fairness, remembering that ‘minimising the error fits majority groups’ [1].</p>
  </li>
  <li>
    <p><strong>Strive for diversity across your organisation:</strong> Whether they realise or not, developer teams will be more susceptible to societal bias if all members come from a specific demographic (regardless of team members’ character and political alignments). Ensuring that all teams in your organisation are diverse across demographic factors (e.g. ethnicity, gender and disabilities) is crucial to flag and mitigate bias througout the AI/ML product lifecycle. In line with the item above, this very often comes at a cost (especially in recruitment), so organisations ought to be willing to pay the cost if they are committed to AI/ML fairness.</p>
  </li>
  <li>
    <p><strong>Auditability is not everything:</strong> Over the last years, there’s been more talk about the audibility of AI/ML products. The goal of auditability is to clearly document when decisions are made and, if necessary, backtrack to an earlier dataset and address the issue at the root. While good documentation and data lineage can be useful in this regard, auditability alone cannot guarantee an ethical use of data.</p>
  </li>
  <li>
    <p><strong>Context is crucial:</strong> AI/ML products are not developed and deployed into echo chambers. They are complex constructs created by humans whose outcomes affect a very large part of society. Therefore, having an understanding of the context surrounding an AI/ML algorithm is crucial for Fair Machine Learning. This affects every stage of the AI/ML product lifecycle: from data acquisition to cleaning, to interpretation of findings, and dissemination of the results. To minimise the chance of disregarding context, here are some questions you and your team can ask during development and deployment of AI/ML products [3], [8]:</p>

    <ul>
      <li>
        <p>What’s the training dataset? How was it curated?</p>
      </li>
      <li>
        <p>What are the potential sources of societal and statistical bias?</p>
      </li>
      <li>
        <p>What’s the subset of the population that will be affected by the algorithm? Did they agree to be involved in the algorithm’s output?</p>
      </li>
      <li>
        <p>How will the deployed algorithm lead to decision-making?</p>
      </li>
      <li>
        <p>How are the stakeholders involved in the product? Does that affect the algorithm’s architecture?</p>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Enable and encourage debates around fair use of data:</strong> These conversations should be a topic that it’s discussed widely in the organisation. It cannot be something that only a couple data scientists in the organisation think about. Organisations thus have the responsibility to create a culture of psychological safety, where people feel comfortable speaking their own mind. This means debating and challenging what fair use of data entails, even if that’s at odds with the organisation’s financial interest.</p>
  </li>
</ul>

<h2 id="conclusions--next-steps"><span class="mr-2">Conclusions &amp; Next Steps</span><a href="#conclusions--next-steps" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>In this article, I hope I have convinced you of the risk that near- and mid-term productionisation of AI/ML can pose to society. We learned some examples of current AI/ML products that misclassify humans based on gender, ethnicity and socioeconomic status. We also learned that Data Ethics is a complex challenge because it encompasses both social, moral and technological areas.</p>

<p>One of the greatest challenges in this topic is that organisations and individuals will develop and deploy biased AI/ML, many times even without realising because of statistical and societal bias. Organisations need to understand that ‘fairness is not one-size-fits-all’ [7] and to mitigate the risk of harmful AI/ML, I proposed some actionable steps that organisations and data practitioners can take. For example, organisations need to enable and encourage debates around the fair use of data, as well as make themselves accountable when they deploy harmful or unethical AI/ML algorithms. For data practitioners specifically, asking meaningful questions will help them understand the context around the human aspect of the data. Because of the many moving components of AI/ML algorithms (both in development and deployment), interpreting context ethically is one of the main challenges that data practitioners will have to face if they aspire to be moral professionals. Whether it is you or your organisation, by ignoring Data Ethics concerns you’re already making a choice, you’re just not aware of it.</p>

<p>Another challenge for data practitioners is to understand how the potential roots of harm can appear as inputs in AI/ML algorithms, and from there architect these algorithms so that they produce fair outcomes instead of unfair ones. By collaborating with charities, at the Good Data Institute (GDI) we spend most of our time trying to showcase to the world how the power of Data Science can be used for social and environmental good.</p>

<p>In the next part of this series, I’ll delve deeper into how we can algorithmically define a sense of fairness to hopefully program it into AI/ML algorithms. This will be a more technical endeavour that will lead me to introduce field Fair Machine Learning (FML). This turns out to be a very difficult task, but in a nutshell, FML aims to address statistical and societal bias by ensuring that the output of AI/ML algorithms doesn’t depend on sensitive inputs in a way that’s considered ‘unfair’. Examples of sensitive inputs include gender, ethnicity, socio-economic status, disability, or sexual orientation [5].</p>

<ul>
  <li>Statistical and structural biases can also be framed at different levels of perspective. For the interested reader, I recommend reading <a href="https://www.multitudes.co/blog/data-ethics-and-mitigating-algorithmic-bias">this article</a> for a discussion of how different biases arise throughout the AI/ML product lifecycle.</li>
</ul>

<h2 id="academic-references"><span class="mr-2">Academic References</span><a href="#academic-references" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><strong>[1]</strong> Chouldechova, A. (2016). Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. <em>arXiv e-prints</em>. https://arxiv.org/abs/1610.07524</p>

<p><strong>[2]</strong> Davis, J. L., Williams, A., &amp; Yang, M. W. (2021). Algorithmic reparation. <em>Big Data &amp; Society</em>, <em>8</em>(2). https://doi.org/10.1177/20539517211044808</p>

<p><strong>[3]</strong> Mitchell, S., Potash, E., Barocas, S., D’Amour, A., &amp; Lum, K. (2018). Prediction-Based Decisions and Fairness: A Catalogue of Choices, Assumptions, and Definitions. <em>arXiv e-prints</em>. https://arxiv.org/abs/1811.07867</p>

<p><strong>[4]</strong> Noble, S. U. (2018). <em>Algorithms of Oppression: How Search Engines Reinforce Racism</em>. New York University Press.</p>

<p><strong>[5]</strong> Oneto, L., &amp; Chiappa, S. (2020). Fairness in Machine Learning. <em>arXiv e-prints</em>. https://arxiv.org/abs/2012.15816</p>

<p><strong>[6]</strong> Shankar, S., Halpern, Y., Breck, E., Atwood, J., Wilson, J., &amp; Sculley, D. (2018). No Classification without Representation: Assessing Geodiversity Issues in Open Data Sets for the Developing World. <em>arXiv e-prints</em>. https://arxiv.org/abs/1811.07867</p>

<p><strong>[7]</strong> Suresh, H., &amp; Guttag, J. (2019). A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle. <em>arXiv e-prints}</em>. https://arxiv.org/abs/1901.10002</p>

<p><strong>[8]</strong> Zook, M., Barocas, S., Boyd, D., Crawford, K., &amp; Keller, E. (2017). Ten simple rules for responsible big data research. <em>PLOS Computational Biology</em>, <em>13</em>(3). https://doi.org/10.1371/journal.pcbi.1005399</p>

</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  
  <div class="post-meta mb-3">
    <i class="far fa-folder-open fa-fw mr-1"></i>
    
      <a href='/categories/blog/'>blog</a>
  </div>
  

  <!-- tags -->
  
  <div class="post-tags">
    <i class="fa fa-tags fa-fw mr-1"></i>
      
      <a href="/tags/ai-ml/"
          class="post-tag no-text-decoration" >ai/ml</a>
      
      <a href="/tags/data-science/"
          class="post-tag no-text-decoration" >data-science</a>
      
      <a href="/tags/ethics/"
          class="post-tag no-text-decoration" >ethics</a>
      
      <a href="/tags/thought-leadership/"
          class="post-tag no-text-decoration" >thought-leadership</a>
      
  </div>
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=The+Productionisation+of+AI%2FML+-+%E2%80%98The+Golden+Era%E2%80%99+or+%E2%80%98The+Wild+West%E2%80%99%3F+-+Raul+Bermejo&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Ffml-part1%2F" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=The+Productionisation+of+AI%2FML+-+%E2%80%98The+Golden+Era%E2%80%99+or+%E2%80%98The+Wild+West%E2%80%99%3F+-+Raul+Bermejo&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Ffml-part1%2F" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Ffml-part1%2F&text=The+Productionisation+of+AI%2FML+-+%E2%80%98The+Golden+Era%E2%80%99+or+%E2%80%98The+Wild+West%E2%80%99%3F+-+Raul+Bermejo" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    
      
        <a href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Ffml-part1%2F" data-toggle="tooltip" data-placement="top"
          title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin">
          <i class="fa-fw fab fa-linkedin"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- pannel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















  <div id="access-lastmod" class="post">
    <div class="panel-heading">Recently Updated</div>
    <ul class="post-content pl-0 pb-1 ml-1 mt-2">
      
        
        
        
      <li><a href="/posts/welcome/">Welcome!</a></li>
      
        
        
        
      <li><a href="/posts/nlp-sms-part1/">NLP analysis on SMS text - part I</a></li>
      
        
        
        
      <li><a href="/posts/nlp-sms-part2/">NLP analysis on SMS text - part II</a></li>
      
        
        
        
      <li><a href="/posts/fml-part1/">The Productionisation of AI/ML - ‘The Golden Era’ or ‘The Wild West’?</a></li>
      
    </ul>
  </div> <!-- #access-lastmod -->



      















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/data-science/">data-science</a>
    
      
      <a class="post-tag" href="/tags/ai-ml/">ai/ml</a>
    
      
      <a class="post-tag" href="/tags/ethics/">ethics</a>
    
      
      <a class="post-tag" href="/tags/nlp/">nlp</a>
    
      
      <a class="post-tag" href="/tags/thought-leadership/">thought-leadership</a>
    

    </div>
  </div>


    </div>

    
      
      



<!-- BS-toc.js will be loaded at medium priority -->
<script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script>

<div id="toc-wrapper" class="pl-0 pr-4 mb-5">
  <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
  <nav id="toc" data-toggle="toc"></nav>
</div>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4">
    
      
      <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  
    
  

  

  

  

  

  


  

  

  

  

  

  


  

  

  

  

  

  








<!-- Fill with the other newlest posts  -->





  <div id="related-posts" class="mt-5 mb-2 mb-sm-4">
    <h3 class="pt-2 mt-1 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/fml-part2/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1686099600"
    data-df="ll"
    >
  Jun  7, 2023
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>AI & Morality - What is Algorithmic Fairness?</h3>
            <div class="text-muted small">
              <p>
                





                This blogpost was originally released through the Good Data Institute (GDI), where I work as a Fellow to to give not-for-profits access to data analytics support &amp;amp; tools for social and environm...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/nlp-sms-part1/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1659522840"
    data-df="ll"
    >
  Aug  3, 2022
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>NLP analysis on SMS text - part I</h3>
            <div class="text-muted small">
              <p>
                





                In this project, I’ll be using Natural Language Processing (NLP) to study an SMS dataset. I’m interested to understand whether NLP can tell us something about the nature of SMS.

For the chosen dat...
              </p>
            </div>
          </div>
        </a>
      </div>
    
      
      
      <div class="card">
        <a href="/posts/nlp-sms-part2/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1659609240"
    data-df="ll"
    >
  Aug  4, 2022
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>NLP analysis on SMS text - part II</h3>
            <div class="text-muted small">
              <p>
                





                In the first part of this Natural Language Processing (NLP) series, I pre-processed a SMS dataset using spaCy. In this post, I’ll use the Python library sklearn to extract some insights from the da...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->


    
      
      <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <a href="/posts/nlp-sms-part2/" class="btn btn-outline-primary"
    prompt="Older">
    <p>NLP analysis on SMS text - part II</p>
  </a>
  

  
  <a href="/posts/fml-part2/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>AI & Morality - What is Algorithmic Fairness?</p>
  </a>
  

</div>

    
      
      <!--  The comments switcher -->


    
  </div>
</div>



        <!-- The Footer -->

<footer class="row pl-3 pr-3">
  <div class="col-12 d-flex justify-content-between align-items-center text-muted pl-0 pr-0">
    <div class="footer-left">
      <p class="mb-0">
        © 2023
        <a href="https://github.com/raul-bermejo">Raul Bermejo</a>.
        
        <span data-toggle="tooltip" data-placement="top"
          title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
        
      </p>
    </div>

    <div class="footer-right">
      <p class="mb-0">
        

        

        Powered by 
          <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
         with 
          <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
         theme.

      </p>
    </div>

  </div>

</footer>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <div id="access-tags">
    <div class="panel-heading">tags</div>
    <div class="d-flex flex-wrap mt-3 mb-1 mr-3">

    
      
      <a class="post-tag" href="/tags/data-science/">data-science</a>
    
      
      <a class="post-tag" href="/tags/ai-ml/">ai/ml</a>
    
      
      <a class="post-tag" href="/tags/ethics/">ethics</a>
    
      
      <a class="post-tag" href="/tags/nlp/">nlp</a>
    
      
      <a class="post-tag" href="/tags/thought-leadership/">thought-leadership</a>
    

    </div>
  </div>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    
      <div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true"
        data-animation="true" data-autohide="false">
        <div class="toast-header">
          <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="pl-2 pr-2 mb-3">A new version of content is available.</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            Update
          </button>
        </div>
      </div>
    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No results found.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!--
  JS selector for site.
-->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script>







  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en-au.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script>








<script defer src="/assets/js/dist/post.min.js"></script>



<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>

